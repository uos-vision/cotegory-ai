{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fba91bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.sparse as sp\n",
    "from scipy import sparse\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3063f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"K\": 300,\n",
    "    \"data_dir\" : \"./dataset\",\n",
    "    \"data_file\" : \"user_problem_mat.npz\",\n",
    "    \"test_batch_size\" : 32,\n",
    "    \"test_ratio\" : 0.3,\n",
    "    \"topks\" : [10,20,50]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ebb28",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c623f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class DATASET(Dataset): \n",
    "    def __init__(self, sparse_matrix, test_ratio=0.3, edit_mat=True, log=True, noise=False, noise_ratio=0.2):\n",
    "        assert type(sparse_matrix) == np.ndarray\n",
    "        \n",
    "        self.sparse_matrix = sparse_matrix\n",
    "        self.edit_mat = edit_mat\n",
    "\n",
    "        self.maxK = max(cfg['topks'])\n",
    "        self.test_dict = {}\n",
    "\n",
    "        self.len_test_ones = 0\n",
    "        self.len_train_ones = 0\n",
    "        \n",
    "        len_test_fail = 0\n",
    "        nz_probs_all = self.sparse_matrix.nonzero()\n",
    "        nz_probs = self.sparse_matrix.sum(0).nonzero()[0]\n",
    "        \n",
    "        if noise:\n",
    "            len_nz_probs = len(nz_probs_all[0])\n",
    "            len_noise = (int)(len_nz_probs * noise_ratio)\n",
    "            noise_idxs = random.sample(range(0,len_nz_probs),len_noise)                                                          \n",
    "            nz_probs_noised = (nz_probs_all[0][noise_idxs],nz_probs_all[1][noise_idxs])\n",
    "            self.sparse_matrix[nz_probs_noised] = 2\n",
    "        \n",
    "        for user in range(len(self.sparse_matrix)):      \n",
    "            items = self.sparse_matrix[user].nonzero()[0]\n",
    "            len_items = len(items)\n",
    "            len_sample = int(len_items * test_ratio)\n",
    "            \n",
    "            if len_sample >= self.maxK :\n",
    "                sample_nums = random.sample(range(0,len_items),len_sample)                                                          \n",
    "                sampled_items = items[sample_nums]\n",
    "                                \n",
    "                #sampled_items = list(set(sampled_items) - slp_idx)\n",
    "                \n",
    "                if edit_mat:\n",
    "                    self.sparse_matrix[user][sampled_items] = 0.\n",
    "                self.test_dict[user] = sampled_items  \n",
    "                self.len_test_ones += len(sampled_items)\n",
    "                self.len_train_ones += (len_items-len(sampled_items))\n",
    "            else:\n",
    "                len_test_fail += 1\n",
    "        \n",
    "        self.nz_probs = self.sparse_matrix.sum(0).nonzero()[0]\n",
    "        if log:\n",
    "            print(f\"\\n{len(nz_probs) - len(self.nz_probs)}\")\n",
    "\n",
    "            print(\"complete making test dict\")\n",
    "            print(f\"length of failed test data : {len_test_fail}\\n\")\n",
    "            print(f\"train dict length : {self.len_train_ones}\")\n",
    "            print(f\"test dict length : {self.len_test_ones}\")\n",
    "            print(f\"set train_test_ratio : {test_ratio}\")\n",
    "            print(f\"result train_test_ratio : {self.len_test_ones / (self.len_train_ones+self.len_test_ones)}\")\n",
    "\n",
    "            # 총 데이터의 개수를 리턴\n",
    "    def __len__(self): \n",
    "        return len(self.sparse_matrix)\n",
    "\n",
    "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx): \n",
    "        x = self.sparse_matrix[idx]\n",
    "        return x\n",
    "            \n",
    "    # 유저가 푼 문제번호 반환\n",
    "    def get_user_pos_items(self, users):\n",
    "        posItems = []\n",
    "        for user in users:\n",
    "            posItems.append(self.sparse_matrix[user].nonzero()[0])\n",
    "        return posItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38a80b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1026\n",
      "complete making test dict\n",
      "length of failed test data : 26\n",
      "\n",
      "train dict length : 493564\n",
      "test dict length : 209924\n",
      "set train_test_ratio : 0.3\n",
      "result train_test_ratio : 0.2984045214701601\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{cfg[\"data_dir\"]}/{cfg[\"data_file\"]}'\n",
    "train_s_mat = sparse.load_npz(data_path).astype(np.float32).toarray()\n",
    "train_dataset = DATASET(train_s_mat, test_ratio=cfg['test_ratio'], noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "69ac3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1040\n",
      "complete making test dict\n",
      "length of failed test data : 26\n",
      "\n",
      "train dict length : 493564\n",
      "test dict length : 209924\n",
      "set train_test_ratio : 0.3\n",
      "result train_test_ratio : 0.2984045214701601\n"
     ]
    }
   ],
   "source": [
    "test_s_mat = sparse.load_npz(data_path).astype(np.float32).toarray()\n",
    "test_dataset = DATASET(test_s_mat, test_ratio=cfg['test_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793a57a",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b391bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def clear():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "#########################################\n",
    "################# Test ##################\n",
    "#########################################\n",
    "\n",
    "def getLabel(test_data, pred_data):\n",
    "    r = []\n",
    "    for i in range(len(test_data)):\n",
    "        groundTrue = test_data[i]\n",
    "        predictTopK = pred_data[i]\n",
    "        pred = list(map(lambda x: x in groundTrue, predictTopK))\n",
    "        pred = np.array(pred).astype(\"float\")\n",
    "        r.append(pred)\n",
    "    return np.array(r).astype('float')\n",
    "\n",
    "def NDCGatK_r(test_data,r,k):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain\n",
    "    rel_i = 1 or 0, so 2^{rel_i} - 1 = 1 or 0\n",
    "    \"\"\"\n",
    "    assert len(r) == len(test_data)\n",
    "    pred_data = r[:, :k]\n",
    "\n",
    "    test_matrix = np.zeros((len(pred_data), k))\n",
    "    for i, items in enumerate(test_data):\n",
    "        length = k if k <= len(items) else len(items)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = np.sum(max_r * 1./np.log2(np.arange(2, k + 2)), axis=1)\n",
    "    dcg = pred_data*(1./np.log2(np.arange(2, k + 2)))\n",
    "    dcg = np.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg/idcg\n",
    "    ndcg[np.isnan(ndcg)] = 0.\n",
    "    return np.sum(ndcg)\n",
    "\n",
    "def RecallPrecision_ATk(test_data, r, k):\n",
    "    \"\"\"\n",
    "    test_data should be a list? cause users may have different amount of pos items. shape (test_batch, k)\n",
    "    pred_data : shape (test_batch, k) NOTE: pred_data should be pre-sorted\n",
    "    k : top-k\n",
    "    \"\"\"\n",
    "    right_pred = r[:, :k].sum(1)\n",
    "    precis_n = k\n",
    "    recall_n = np.array([len(test_data[i]) for i in range(len(test_data))])\n",
    "    recall = np.sum(right_pred/recall_n)\n",
    "    precis = np.sum(right_pred)/precis_n\n",
    "    return {'recall': recall, 'precision': precis}\n",
    "\n",
    "def test_one_batch(X, cfg):\n",
    "    sorted_items = X[0].numpy()\n",
    "    groundTrue = X[1]\n",
    "    r = getLabel(groundTrue, sorted_items)\n",
    "    pre, recall, ndcg = [], [], []\n",
    "    for k in cfg['topks']:\n",
    "        ret = RecallPrecision_ATk(groundTrue, r, k)\n",
    "        pre.append(ret['precision'])\n",
    "        recall.append(ret['recall'])\n",
    "        ndcg.append(NDCGatK_r(groundTrue,r,k))\n",
    "    return {'recall':np.array(recall), \n",
    "            'precision':np.array(pre), \n",
    "            'ndcg':np.array(ndcg)}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}    \n",
    "    \n",
    "def add_to_user_problem_mat(idx, id, user_problem_mat : np.array):\n",
    "    data = requests.get(f'https://www.acmicpc.net/user/{id}', headers=headers)\n",
    "    soup = BeautifulSoup(data.text, 'html.parser')\n",
    "    trs = soup.select('div.problem-list')\n",
    "\n",
    "    for tr in trs:\n",
    "        problem_nums = tr.select('a')\n",
    "            \n",
    "        for problem_num in problem_nums :\n",
    "\n",
    "            problem_num = int(problem_num.text) - 1000\n",
    "            #print(problem_num)\n",
    "            try:\n",
    "                user_problem_mat[idx,problem_num] = 1\n",
    "            except:\n",
    "                print(\"범위를 벗어난 문제 번호 : \" + str(problem_num))\n",
    "\n",
    "def print_result(res):\n",
    "    print(f'precision : {res[\"precision\"]}')\n",
    "    print(f'recall : {res[\"recall\"]}')\n",
    "    print(f'ndcg : {res[\"ndcg\"]}')     \n",
    "    \n",
    "def random_sample(num_col, num_row, min_ratio=0.01, max_ratio=0.02):\n",
    "    test_s_mat_rand = np.zeros((num_col,num_row))\n",
    "\n",
    "    for i in range(num_col):\n",
    "        min_num = int(num_row * min_ratio)\n",
    "        max_num = int(num_row * max_ratio)\n",
    "        num_sample = random.sample(range(min_num,max_num),1)[0]\n",
    "\n",
    "        num_list = random.sample(range(num_row),num_sample)\n",
    "        \n",
    "        test_s_mat_rand[i][num_list] = 1\n",
    "    \n",
    "    return test_s_mat_rand\n",
    "\n",
    "def print_sparcity(mat):\n",
    "    if type(mat) != np.array : mat = np.array(mat)\n",
    "    \n",
    "    len_zeros = len(np.where(mat == 0)[0])\n",
    "    len_ones = len(np.where(mat != 0)[0])\n",
    "    sparcity = len_zeros / (len_zeros + len_ones)\n",
    "    print(f\"0 개수 : {len_zeros}\")\n",
    "    print(f\"1 개수 : {len_ones}\")\n",
    "    print(f\"sparsity : {sparcity}\")\n",
    "\n",
    "def minibatch(*tensors, **kwargs):\n",
    "\n",
    "    batch_size = kwargs.get('batch_size', cfg['test_batch_size'])\n",
    "\n",
    "    if len(tensors) == 1:\n",
    "        tensor = tensors[0]\n",
    "        for i in range(0, len(tensor), batch_size):\n",
    "            yield tensor[i:i + batch_size]\n",
    "    else:\n",
    "        for i in range(0, len(tensors[0]), batch_size):\n",
    "            yield tuple(x[i:i + batch_size] for x in tensors)\n",
    "\n",
    "def test_loop(dataset, Recmodel, cfg, exclude=True, addPos=False, is_rand=False):    \n",
    "    u_batch_size = cfg['test_batch_size']\n",
    "    testDict: dict = dataset.test_dict\n",
    "        \n",
    "    max_K = max(cfg['topks'])\n",
    "    results = {'precision': np.zeros(len(cfg['topks'])),\n",
    "               'recall': np.zeros(len(cfg['topks'])),\n",
    "               'ndcg': np.zeros(len(cfg['topks']))}\n",
    "    \n",
    "    users = list(testDict.keys())\n",
    "    try:\n",
    "        assert u_batch_size <= len(users) / 10\n",
    "    except AssertionError:\n",
    "        print(f\"test_u_batch_size is too big for this dataset, try a small one {len(users) // 10}\")\n",
    "    users_list = []\n",
    "    rating_list = []\n",
    "    groundTrue_list = []\n",
    "    # auc_record = []\n",
    "    # ratings = []\n",
    "    total_batch = len(users) // u_batch_size + 1\n",
    "    for batch_users in minibatch(users, batch_size=u_batch_size):\n",
    "        groundTrue = [list(testDict[u]) for u in batch_users]\n",
    "        _batch_users = dataset.sparse_matrix[batch_users]\n",
    "\n",
    "        if is_rand:\n",
    "            rating_K = torch.Tensor([random.sample(range(dataset.sparse_matrix.shape[1]),max_K) for i in range(u_batch_size)])\n",
    "        else:\n",
    "            rating = Recmodel.getUsersRating(_batch_users)\n",
    "\n",
    "            #rating = rating.cpu()\n",
    "            #print('Exclude Rated Item')\n",
    "            allPos = dataset.get_user_pos_items(batch_users)\n",
    "\n",
    "            if exclude:\n",
    "                exclude_index = []\n",
    "                exclude_items = []\n",
    "                for range_i, items in enumerate(allPos):\n",
    "                    exclude_index.extend([range_i] * len(items))\n",
    "                    exclude_items.extend(items)\n",
    "                rating[exclude_index, exclude_items] = -(1<<10)\n",
    "\n",
    "            if addPos:\n",
    "                for i in range(len(batch_users)):\n",
    "                    groundTrue[i].extend(allPos[i])\n",
    "\n",
    "            _, rating_K = torch.topk(torch.FloatTensor(rating), k=max_K)\n",
    "\n",
    "            del rating    \n",
    "        \n",
    "        users_list.append(batch_users)\n",
    "        rating_list.append(rating_K.cpu())\n",
    "        groundTrue_list.append(groundTrue)\n",
    "\n",
    "    assert total_batch == len(users_list)\n",
    "    X = zip(rating_list, groundTrue_list)\n",
    "    pre_results = []\n",
    "    for x in X:\n",
    "        pre_results.append(test_one_batch(x,cfg))\n",
    "    scale = float(u_batch_size/len(users))\n",
    "    for result in pre_results:\n",
    "        results['recall'] += result['recall']\n",
    "        results['precision'] += result['precision']\n",
    "        results['ndcg'] += result['ndcg']\n",
    "    results['recall'] /= float(len(users))\n",
    "    results['precision'] /= float(len(users))\n",
    "    results['ndcg'] /= float(len(users))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ea597",
   "metadata": {},
   "source": [
    "# EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f5c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    \"\"\"\n",
    "    Embarrassingly Shallow Autoencoders model class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_):\n",
    "        self.B = None\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def train(self, interaction_matrix):\n",
    "        \"\"\"\n",
    "        train pass\n",
    "        :param interaction_matrix: interaction_matrix\n",
    "        \"\"\"\n",
    "        # X ~= X * B인 B구하는 것이 목표\n",
    "        X = interaction_matrix\n",
    "        G = X.T @ X\n",
    "        diag = list(range(G.shape[0]))\n",
    "        G[diag, diag] += self.lambda_\n",
    "        P = np.linalg.inv(G) # P는 G의 inverse matrix\n",
    "\n",
    "        # B = P * (X^T * X − diagMat(γ))\n",
    "        self.B = P / -np.diag(P)\n",
    "        min_dim = min(*self.B.shape)\n",
    "        self.B[range(min_dim), range(min_dim)] = 0\n",
    "\n",
    "    def forward(self, user_row):\n",
    "        \"\"\"\n",
    "        forward pass\n",
    "        \"\"\"\n",
    "        return user_row @ self.B\n",
    "    \n",
    "    def getUsersRating(self, user_row : np.array):\n",
    "        return self.forward(user_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2175eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215.03211 sec\n"
     ]
    }
   ],
   "source": [
    "## EASE 훈련\n",
    "start = time.time()\n",
    "\n",
    "ease = EASE(cfg[\"K\"])\n",
    "\n",
    "ease.train(train_dataset.sparse_matrix)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"{end - start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a672cf8",
   "metadata": {},
   "source": [
    "### 기존 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e4bd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : [0.96204527 0.92791027 0.79650768]\n",
      "recall : [0.12558379 0.24103551 0.50557657]\n",
      "ndcg : [0.9682439  0.94235696 0.83906388]\n"
     ]
    }
   ],
   "source": [
    "print_result(test_loop(test_dataset, ease, cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3abe0c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : [0.89854487 0.85394099 0.71822959]\n",
      "recall : [0.11723741 0.22177614 0.45765978]\n",
      "ndcg : [0.9096446  0.87465968 0.76498216]\n"
     ]
    }
   ],
   "source": [
    "print_result(test_loop(train_dataset, ease, cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df95a33",
   "metadata": {},
   "source": [
    "### 값이 1인 데이터의 20%를 2로 바꿨을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7af54d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : [0.94987874 0.91014551 0.7803557 ]\n",
      "recall : [0.12378721 0.23590224 0.49495839]\n",
      "ndcg : [0.95917875 0.92821729 0.82428984]\n"
     ]
    }
   ],
   "source": [
    "print_result(test_loop(test_dataset, ease, cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4224ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : [0.85339531 0.80697251 0.67582862]\n",
      "recall : [0.11112284 0.20912132 0.43074015]\n",
      "ndcg : [0.86815999 0.83057257 0.72293857]\n"
     ]
    }
   ],
   "source": [
    "print_result(test_loop(train_dataset, ease, cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1d2e3",
   "metadata": {},
   "source": [
    "### 랜덤으로 추천한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2783c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : [0.0025869  0.00264753 0.00306386]\n",
      "recall : [0.00031165 0.00063393 0.00183674]\n",
      "ndcg : [0.00266419 0.00268368 0.00297329]\n"
     ]
    }
   ],
   "source": [
    "print_result(test_loop(train_dataset, ease, cfg, is_rand=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
